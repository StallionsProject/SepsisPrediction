{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.linear_model as linear\n",
    "import sklearn.model_selection as selection\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "databasePath = \"../eICU/training/\"\n",
    "exportPath = \"../eICU/training/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        patientid  temperature_min  temperature_max  temperature_mean  \\\n0         1412030          38.1204          38.1204           38.1204   \n1         1412271          37.6965          38.1204           38.0819   \n2         1412290          38.1204          38.1204           38.1204   \n3         1412660          37.4000          38.0000           37.7832   \n4         1412840          38.1204          38.1204           38.1204   \n...           ...              ...              ...               ...   \n406022   33532516          32.2000          37.7000           35.3112   \n406023   33532517          32.2000          37.4000           34.5467   \n406024   33532518          32.2000          36.8000           34.1643   \n406025   33532540          38.1204          38.1204           38.1204   \n406026   33532630          38.1204          38.1204           38.1204   \n\n        temperature_std  temperature_kurtosis  temperature_skew  \\\n0                0.0000                0.0000            0.0000   \n1                0.1278               11.0000           -3.3166   \n2                0.0000                0.0000            0.0000   \n3                0.1822               -0.3726           -0.6013   \n4                0.0000                0.0000            0.0000   \n...                 ...                   ...               ...   \n406022           2.1057               -1.7574           -0.2178   \n406023           1.8862               -1.7703            0.2656   \n406024           1.7398               -1.4068            0.6213   \n406025           0.0000                0.0000            0.0000   \n406026           0.0000                0.0000            0.0000   \n\n        temperature_median  heartrate_min  heartrate_max  ...  \\\n0                  38.1204           68.0          120.0  ...   \n1                  38.1204          103.0          112.0  ...   \n2                  38.1204           57.0           75.0  ...   \n3                  37.8000           84.0          109.0  ...   \n4                  38.1204           70.0          106.0  ...   \n...                    ...            ...            ...  ...   \n406022             36.6000           51.0          104.0  ...   \n406023             33.4000           51.0          104.0  ...   \n406024             33.1000           60.0          104.0  ...   \n406025             38.1204           72.0           83.0  ...   \n406026             38.1204           69.0           95.0  ...   \n\n        creatinine_skew  creatinine_median  urineoutputbyweight_min  \\\n0               -1.4140             0.6875                   6.9586   \n1                0.2131             1.4000                   2.4331   \n2                0.1274             1.2345                   4.4543   \n3               -0.5963             1.6136                   0.8306   \n4               -0.0575             1.0584                   0.6420   \n...                 ...                ...                      ...   \n406022          -0.0645             2.6469                   0.0980   \n406023           0.1481             2.5493                   0.0980   \n406024           0.0064             2.4888                   0.0980   \n406025          -2.1039             2.2769                   0.3576   \n406026           0.0000             1.0600                   6.9586   \n\n        urineoutputbyweight_max  urineoutputbyweight_mean  \\\n0                        6.9586                    6.9586   \n1                        2.4331                    2.4331   \n2                        4.4543                    4.4543   \n3                        3.7375                    3.6347   \n4                        1.7976                    1.5475   \n...                         ...                       ...   \n406022                   5.6373                    1.0889   \n406023                   5.6373                    0.9832   \n406024                   5.6373                    1.0385   \n406025                  19.0703                    3.7475   \n406026                   6.9586                    6.9586   \n\n        urineoutputbyweight_std  urineoutputbyweight_kurtosis  \\\n0                        0.0000                        0.0000   \n1                        0.0000                        0.0000   \n2                        0.0000                        0.0000   \n3                        0.4814                       21.5211   \n4                        0.2748                        2.0620   \n...                         ...                           ...   \n406022                   0.9895                        3.4195   \n406023                   1.0570                        3.9619   \n406024                   1.1231                        2.9569   \n406025                   2.6719                       13.1009   \n406026                   0.0000                        0.0000   \n\n        urineoutputbyweight_skew  urineoutputbyweight_median  diagnosis  \n0                         0.0000                      6.9586        0.0  \n1                         0.0000                      2.4331        1.0  \n2                         0.0000                      4.4543        0.0  \n3                        -4.7383                      3.7375        0.0  \n4                        -1.6282                      1.5956        0.0  \n...                          ...                         ...        ...  \n406022                    1.6831                      0.8171        1.0  \n406023                    1.9491                      0.6334        1.0  \n406024                    1.7434                      0.6010        1.0  \n406025                    3.2470                      2.3838        0.0  \n406026                    0.0000                      6.9586        0.0  \n\n[406027 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patientid</th>\n      <th>temperature_min</th>\n      <th>temperature_max</th>\n      <th>temperature_mean</th>\n      <th>temperature_std</th>\n      <th>temperature_kurtosis</th>\n      <th>temperature_skew</th>\n      <th>temperature_median</th>\n      <th>heartrate_min</th>\n      <th>heartrate_max</th>\n      <th>...</th>\n      <th>creatinine_skew</th>\n      <th>creatinine_median</th>\n      <th>urineoutputbyweight_min</th>\n      <th>urineoutputbyweight_max</th>\n      <th>urineoutputbyweight_mean</th>\n      <th>urineoutputbyweight_std</th>\n      <th>urineoutputbyweight_kurtosis</th>\n      <th>urineoutputbyweight_skew</th>\n      <th>urineoutputbyweight_median</th>\n      <th>diagnosis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1412030</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>38.1204</td>\n      <td>68.0</td>\n      <td>120.0</td>\n      <td>...</td>\n      <td>-1.4140</td>\n      <td>0.6875</td>\n      <td>6.9586</td>\n      <td>6.9586</td>\n      <td>6.9586</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>6.9586</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1412271</td>\n      <td>37.6965</td>\n      <td>38.1204</td>\n      <td>38.0819</td>\n      <td>0.1278</td>\n      <td>11.0000</td>\n      <td>-3.3166</td>\n      <td>38.1204</td>\n      <td>103.0</td>\n      <td>112.0</td>\n      <td>...</td>\n      <td>0.2131</td>\n      <td>1.4000</td>\n      <td>2.4331</td>\n      <td>2.4331</td>\n      <td>2.4331</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.4331</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1412290</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>38.1204</td>\n      <td>57.0</td>\n      <td>75.0</td>\n      <td>...</td>\n      <td>0.1274</td>\n      <td>1.2345</td>\n      <td>4.4543</td>\n      <td>4.4543</td>\n      <td>4.4543</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>4.4543</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1412660</td>\n      <td>37.4000</td>\n      <td>38.0000</td>\n      <td>37.7832</td>\n      <td>0.1822</td>\n      <td>-0.3726</td>\n      <td>-0.6013</td>\n      <td>37.8000</td>\n      <td>84.0</td>\n      <td>109.0</td>\n      <td>...</td>\n      <td>-0.5963</td>\n      <td>1.6136</td>\n      <td>0.8306</td>\n      <td>3.7375</td>\n      <td>3.6347</td>\n      <td>0.4814</td>\n      <td>21.5211</td>\n      <td>-4.7383</td>\n      <td>3.7375</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1412840</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>38.1204</td>\n      <td>70.0</td>\n      <td>106.0</td>\n      <td>...</td>\n      <td>-0.0575</td>\n      <td>1.0584</td>\n      <td>0.6420</td>\n      <td>1.7976</td>\n      <td>1.5475</td>\n      <td>0.2748</td>\n      <td>2.0620</td>\n      <td>-1.6282</td>\n      <td>1.5956</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>406022</td>\n      <td>33532516</td>\n      <td>32.2000</td>\n      <td>37.7000</td>\n      <td>35.3112</td>\n      <td>2.1057</td>\n      <td>-1.7574</td>\n      <td>-0.2178</td>\n      <td>36.6000</td>\n      <td>51.0</td>\n      <td>104.0</td>\n      <td>...</td>\n      <td>-0.0645</td>\n      <td>2.6469</td>\n      <td>0.0980</td>\n      <td>5.6373</td>\n      <td>1.0889</td>\n      <td>0.9895</td>\n      <td>3.4195</td>\n      <td>1.6831</td>\n      <td>0.8171</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <td>406023</td>\n      <td>33532517</td>\n      <td>32.2000</td>\n      <td>37.4000</td>\n      <td>34.5467</td>\n      <td>1.8862</td>\n      <td>-1.7703</td>\n      <td>0.2656</td>\n      <td>33.4000</td>\n      <td>51.0</td>\n      <td>104.0</td>\n      <td>...</td>\n      <td>0.1481</td>\n      <td>2.5493</td>\n      <td>0.0980</td>\n      <td>5.6373</td>\n      <td>0.9832</td>\n      <td>1.0570</td>\n      <td>3.9619</td>\n      <td>1.9491</td>\n      <td>0.6334</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <td>406024</td>\n      <td>33532518</td>\n      <td>32.2000</td>\n      <td>36.8000</td>\n      <td>34.1643</td>\n      <td>1.7398</td>\n      <td>-1.4068</td>\n      <td>0.6213</td>\n      <td>33.1000</td>\n      <td>60.0</td>\n      <td>104.0</td>\n      <td>...</td>\n      <td>0.0064</td>\n      <td>2.4888</td>\n      <td>0.0980</td>\n      <td>5.6373</td>\n      <td>1.0385</td>\n      <td>1.1231</td>\n      <td>2.9569</td>\n      <td>1.7434</td>\n      <td>0.6010</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <td>406025</td>\n      <td>33532540</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>38.1204</td>\n      <td>72.0</td>\n      <td>83.0</td>\n      <td>...</td>\n      <td>-2.1039</td>\n      <td>2.2769</td>\n      <td>0.3576</td>\n      <td>19.0703</td>\n      <td>3.7475</td>\n      <td>2.6719</td>\n      <td>13.1009</td>\n      <td>3.2470</td>\n      <td>2.3838</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>406026</td>\n      <td>33532630</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>38.1204</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>38.1204</td>\n      <td>69.0</td>\n      <td>95.0</td>\n      <td>...</td>\n      <td>0.0000</td>\n      <td>1.0600</td>\n      <td>6.9586</td>\n      <td>6.9586</td>\n      <td>6.9586</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>6.9586</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>406027 rows Ã— 58 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalFeatures = pd.read_csv(databasePath + '/finalFeatures.csv')\n",
    "finalFeatures = finalFeatures.fillna(0) # fills nan from kurtosis and skew\n",
    "finalFeatures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cleaning data and Sorting to Input and Target Arrays"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x = [] # input (attributes)\n",
    "y = [] # output (targets)\n",
    "\n",
    "x = finalFeatures.iloc[:, 1:56].values\n",
    "y = finalFeatures.iloc[:, 57].values\n",
    "\n",
    "x = MinMaxScaler().fit_transform(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setting up Models for Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class MoonModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_func = nn.BCELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return None\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        probs = self.forward(x)\n",
    "        return self.loss_func(probs, y)\n",
    "\n",
    "    def predict_proba(self, x, as_numpy=False):\n",
    "        res = self.forward(x)\n",
    "        if as_numpy:\n",
    "            res = res.detach().numpy()\n",
    "        return res\n",
    "\n",
    "    def predict(self, x, threshold=0.5, as_numpy=False):\n",
    "        probs = self.predict_proba(x, as_numpy)\n",
    "        return probs > threshold\n",
    "\n",
    "    def fit(self, x, y, epochs=1000, lr=0.1, lam=0):\n",
    "        optimizer = optim.RMSprop(self.parameters(), lr=lr)\n",
    "        loss_curve = []\n",
    "        for _ in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            loss_val = self.loss(x, y) + self.regularize(lam)\n",
    "            loss_curve.append(loss_val.data.item())\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "        return loss_curve\n",
    "\n",
    "    def regularize(self, lam):\n",
    "        loss_val = 0\n",
    "        for p in self.parameters():\n",
    "            loss_val += lam * th.norm(p)\n",
    "        return loss_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class NNModel(MoonModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(55, 55, bias=True)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.l2 = nn.Linear(55, 1, bias=True)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "    def get_intermediary(self, x):\n",
    "        res = self.l1(x)\n",
    "        res = self.act1(res)\n",
    "        return res\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.l1(x)\n",
    "        res = self.act1(res)\n",
    "        res = self.l2(res)\n",
    "        res = self.act2(res)\n",
    "        return res\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Applying Logistic Regression and Neural Network Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# device = th.device(\"cuda:0\" if th.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kf = selection.KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "f1_lr = []\n",
    "f1_nn = []\n",
    "\n",
    "def plot_loss(loss_curve):\n",
    "    plt.plot(list(range(len(loss_curve))), loss_curve)\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    lr = linear.LogisticRegression(solver='lbfgs')\n",
    "    lr.fit(X_train, y_train)\n",
    "    predictions = lr.predict(X_test)\n",
    "    probs = lr.predict_proba(X_test)[:,1]\n",
    "    f1_lr.append(metrics.f1_score(y_test, predictions))\n",
    "\n",
    "    X_train = th.tensor(X_train, dtype=th.float32)\n",
    "    X_test = th.tensor(X_test, dtype=th.float32)\n",
    "    y_train = th.tensor(y_train, dtype=th.float32).view(-1, 1)\n",
    "    y_test = th.tensor(y_test, dtype=th.float32).view(-1, 1)\n",
    "\n",
    "    # X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "    # X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "    nn1 = NNModel()\n",
    "    # nn1.to(device)\n",
    "\n",
    "    curve = nn1.fit(X_train, y_train, lam=0.01)\n",
    "    predictions = nn1.predict(X_test, as_numpy=True)\n",
    "    probs = nn1.predict_proba(X_test, as_numpy=True)\n",
    "    f1_nn.append(metrics.f1_score(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Comparing Statistical Results for the Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Logistic Regression Model Mean: \", np.mean(f1_lr))\n",
    "print(\"Logistic Regression Model Standard Deviation: \", np.std(f1_lr))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Neural Network Model Mean: \", np.mean(f1_nn))\n",
    "print(\"Neural Network Model Standard Deviation: \", np.std(f1_nn))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"T-Test comparing the Logistic Regression and the Neural Network Models: \")\n",
    "print(stats.ttest_rel(f1_lr, f1_nn))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using a significance level of 0.05, we see that the difference between logistic regression\n",
    "and neural network are not statistically significant."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Intermediary Workings of the Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_transformed = th.tensor(x, dtype=th.float32)\n",
    "representations = nn1.get_intermediary(X_transformed)\n",
    "representations = representations.detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = np.array(['tab:red' if cl == 0 else 'tab:blue' for cl in y])\n",
    "plt.scatter(representations[:,0], representations[:,1], c=colors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}